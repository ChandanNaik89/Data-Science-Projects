libraries to include
import tensorflow as tf
import os
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats

## reading data set
data = pd.read_csv("D:\\ExcelR\\project\\Data.csv",encoding='latin1',low_memory=False)

# data set information
data.head()             
data.tail()            
data.info()             
len(data.columns)      
data.describe()         
data.size               
len(data)               
print(data.shape)     
data.nunique()          
data_cat.columns.tolist()   
data.dtypes            
print(data.describe())  
data.isnull()          
data.isnull().sum()    


#### subtype of all catagorical variable
data['terms'].unique()
data['State'].unique()
data['purpose'].unique()
data['grade'].unique()
data['sub_grade'].unique()
data['Emp_designation'].unique()
data['Experience'].unique()
data['home_ownership'].unique()
data['verification_status'].unique()
data['application_type'].unique()
data['verification_status_joint'].unique()

## corelation of dataset
corelation = data.corr()
ax = sns.set(rc={'figure.figsize':(20,12)})
sns.heatmap(corelation, ax = ax, cmap ="YlGnBu", linewidths = 0.1) 
sns.heatmap(corelation, xticklabels=corelation.columns, yticklabels=corelation.columns, annotate = True)

corelation = data.corr()
print(corelation["total revol_bal"])    ## co relation between target varibale

data.corr(method ='pearson')            ## co relation between all variable

## dist plot
sns.distplot(data['total revol_bal'])
sns.distplot(data['loan_amnt'])
sns.distplot(data['Rate_of_intrst'])
sns.distplot(data['annual_inc'])
sns.distplot(data['tot_colle_amt'])
sns.distplot(data['tot_colle_amt'])

#### scater plot
sns.scatterplot(x = 'annual_inc', y = 'total revol_bal', data = data)
sns.scatterplot(x = 'tot_curr_bal', y = 'total revol_bal', data = data)
sns.scatterplot(x = 'loan_amnt', y = 'total revol_bal', data = data)
sns.scatterplot(x = 'tot_curr_bal', y = 'total revol_bal', hue="home_ownership", data = data)
sns.scatterplot(x = 'Rate_of_intrst', y = 'total revol_bal', hue="grade", data = data)
sns.scatterplot(x = 'loan_amnt', y = 'total revol_bal', hue="verification_status", data = data)
sns.scatterplot(x = 'annual_inc', y = 'total revol_bal', hue="application_type", data = data)
sns.scatterplot(x = 'total_credits', y = 'total revol_bal', hue="home_ownership", data = data)

## bar plot
fig_dims = (25, 5)
fig, ax = plt.subplots(figsize=fig_dims)
sns.barplot(x = "purpose", y = "loan_amnt ", ax=ax, data=data)

sns.barplot(x = 'home_ownership', y = 'total revol_bal', data = data)
sns.barplot(x = 'home_ownership', y = 'Rate_of_intrst', data = data)
sns.barplot(x = 'home_ownership', y = 'annual_inc', data = data)

sns.catplot(x="verification_status", y="annual_inc", hue="home_ownership", kind="bar", data=data);
sns.catplot(x="application_type", y="Rate_of_intrst", hue="grade", kind="bar", data=data);
sns.catplot(x="application_type", y="Rate_of_intrst", hue="Experience", kind="bar", data=data);
sns.catplot(x="application_type", y="total revol_bal", hue="verification_status", kind="bar", data=data);

#### box plot
sns.boxplot(data=data,x=data["total revol_bal"])
sns.boxplot(data=data,x=data["loan_amnt "])
sns.boxplot(data=data,x=data["annual_inc"])
sns.boxplot(data=data,x=data["pub_rec"])
sns.boxplot(data=data,x=data["tot_colle_amt"])
sns.boxplot(data=data,x=data["tot_curr_bal"])
sns.boxplot(data=data,x=data["total_credits"])
sns.boxplot(data=data,x=data["total_rec_int"])


## histogtam plot of all varible 
data.hist(bins=30, figsize=(20, 10))

## checking any duplcate
##data.drop_duplicates(subset='member_id ', keep="last")
##df = data.drop_duplicates()
##df.count()
##data.count()


## missing value
data_selected = data.drop(["member_id ","batch_ID ","Emp_designation","mths_since_last_major_derog","total_rec_late_fee","tot_colle_amt","acc_now_delinq",
                           "verification_status_joint","mths_since_last_record","mths_since_last_delinq","collection_recovery_fee","collections_12_mths_ex_med"], axis=1)

data_selected1 = data.drop(["member_id ","batch_ID ","loan_amnt ","acc_now_delinq","grade","sub_grade","total_credits",
                           "Rate_of_intrst","annual_inc","mths_since_last_delinq","numb_credit","State"], axis=1)


data_selected.shape
data_selected.isnull().sum()

data_num = data_selected1.select_dtypes(include = ['float64', 'int64'])
data_num.columns.tolist()
data_num.fillna(data_num.median(), inplace=True)
data_num.isnull().sum()
data_num.tail()
data_num.shape

# Normalization function 
def norm_func(i):
    x = (i-i.min())	/	(i.max()	-	i.min())
    return (x)

cols = list(data_num)
cols.insert(0, cols.pop(cols.index('total revol_bal')))
cols
data_num = data_num.ix[:, cols]

# Normalized data frame (considering the numerical part of data)
df_norm = norm_func(data_num.iloc[:,1:])
total = data_selected['total revol_bal']
data_num = pd.concat([data_num.reset_index(drop=True), total], axis=1)


data_cat = data_selected1.select_dtypes(include = ['object'])
data_cat.isnull().sum()
data_cat = data_cat.apply(lambda x:x.fillna(x.value_counts().index[0]))
data_cat.iloc[:,-5]

data_final = pd.concat([data_num.reset_index(drop=True), data_cat], axis=1)
data_final.isnull().sum()
data_final.shape

## transform to numeric var
### lable encoder
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
data_final.dtypes

data_final["terms"] = le.fit_transform(data_final.terms)
data_final["Experience"] = le.fit_transform(data_final.Experience)
#data_final["grade"] = le.fit_transform(data_final.grade)
#data_final["sub_grade"] = le.fit_transform(data_final.sub_grade)
data_final["purpose"] = le.fit_transform(data_final.purpose)
#data_final["State"] = le.fit_transform(data_final.State)
data_final["Experience"] = le.fit_transform(data_final.Experience)
data_final["home_ownership"] = le.fit_transform(data_final.home_ownership)
data_final["application_type"] = le.fit_transform(data_final.application_type)
data_final["last_week_pay"] = le.fit_transform(data_final.last_week_pay)
data_final["initial_list_status"] = le.fit_transform(data_final.initial_list_status)
data_final["Emp_designation"] = le.fit_transform(data_final.Emp_designation)
data_final["verification_status_joint"] = le.fit_transform(data_final.verification_status_joint)
data_final["verification_status"] = le.fit_transform(data_final.verification_status)

data_final.dtypes
data_final.shape


data_final_outliers = data_final ### outlier data set
data_final_outliers.dtypes

## outlier handeling
#df = data_final[["loan_amnt ","Rate_of_intrst","tot_curr_bal","annual_inc","total revol_bal","total_credits","numb_credit"]]
df = data_final[["total revol_bal"]]

df.columns.tolist()
df.isnull().sum()

fig_dims = (9, 5)
fig, ax = plt.subplots(figsize=fig_dims)
df.boxplot(ax=ax)

for col in df.columns:
    percentiles = df[col].quantile([0.10,0.90]).values
    df[col][df[col] <= percentiles[0]] = percentiles[0]
    df[col][df[col] >= percentiles[1]] = percentiles[1]
    

fig_dims = (9, 5)
fig, ax = plt.subplots(figsize=fig_dims)
df.boxplot(ax=ax,patch_artist=True)  
  
data_final['loan_amnt '] = df['loan_amnt '].replace(['loan_amnt '],'loan_amnt ')
data_final['Rate_of_intrst'] = df['Rate_of_intrst'].replace(['Rate_of_intrst'],'Rate_of_intrst')
data_final['tot_curr_bal'] = df['tot_curr_bal'].replace(['tot_curr_bal'],'tot_curr_bal')
data_final['annual_inc'] = df['annual_inc'].replace(['annual_inc'],'annual_inc')
data_final['total revol_bal'] = df['total revol_bal'].replace(['total revol_bal'],'total revol_bal')
data_final['total_credits'] = df['total_credits'].replace(['total_credits'],'total_credits')
data_final['numb_credit'] = df['numb_credit'].replace(['numb_credit'],'numb_credit')
sns.boxplot(data=data_final,x=data_final["total revol_bal"])


### checking normalization
## density plot
data_final.columns.tolist()

sns.distplot(data_final['total revol_bal'])
sns.distplot(data_final['loan_amnt '])
sns.distplot(data_final['Rate_of_intrst'])
sns.distplot(data_final['annual_inc'])
sns.distplot(data_final['tot_colle_amt'])
sns.distplot(data['tot_colle_amt'])

## by histogram
data_final.hist(bins=30, figsize=(20, 10))

## by shapiro test
stats.shapiro(data_final["loan_amnt "])   ## 0.91 >0.05 normaly distributed
stats.shapiro(data_final["Rate_of_intrst"])
stats.shapiro(data_final["annual_inc"])
stats.shapiro(data_final["debt_income_ratio"])
stats.shapiro(data_final["delinq_2yrs"])
stats.shapiro(data_final["mths_since_last_delinq"])
stats.shapiro(data_final["numb_credit"])
stats.shapiro(data_final["total revol_bal"])
stats.shapiro(data_final["tot_colle_amt"])  ## not normally distributed
stats.shapiro(data_final["tot_curr_bal"])   ###
stats.shapiro(data_final["last_week_pay"])   ###
stats.shapiro(data_final["recoveries"])   ###
stats.shapiro(data_final["mths_since_last_record"])   ### 
stats.shapiro(data_final["total_rec_late_fee"])   ### 


from statsmodels.stats.outliers_influence import variance_inflation_factor

def calc_vif(X):

    # Calculating VIF
    vif = pd.DataFrame()
    vif["variables"] = X.columns
    vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
    return(vif)
    
X = data_final.iloc[:,:-1]
calc_vif(X)
